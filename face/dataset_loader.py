# -*- coding: utf-8 -*-
"""dataset_loader.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_qdmbZnZ1YkA7fU_uCYM2rliTmIHDwDi
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("msambare/fer2013")

print("Path to dataset files:", path)

# dataset_loader.py
import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

class KaggleFER2013Loader:
    def __init__(self):
        self.emotions = {
            'angry': 0,
            'disgust': 1,
            'fear': 2,
            'happy': 3,
            'sad': 4,
            'surprise': 5,
            'neutral': 6
        }

        self.emotion_names = {
            0: 'Angry',
            1: 'Disgust',
            2: 'Fear',
            3: 'Happy',
            4: 'Sad',
            5: 'Surprise',
            6: 'Neutral'
        }

    def find_kaggle_dataset(self):
        """Find the FER2013 dataset in Kaggle environment"""
        possible_paths = [
            '/kaggle/input/fer2013',
            '/kaggle/input/facial-expression-recognitionfer-challenge',
            '/kaggle/input/fer2013/train',
            '/kaggle/input/fer2013/test'
        ]

        for path in possible_paths:
            if os.path.exists(path):
                print(f"âœ… Found dataset at: {path}")
                return path
        return None

    def load_kaggle_dataset(self, img_size=(48, 48)):
        """Load dataset from Kaggle input directory"""
        print("ğŸ” Searching for FER2013 dataset in Kaggle...")

        base_path = self.find_kaggle_dataset()
        if base_path is None:
            print("âŒ Could not find FER2013 dataset in Kaggle input")
            print("ğŸ’¡ Make sure you've added the dataset to your notebook")
            return None, None, None, None

        # Check different possible structures
        train_paths = [
            os.path.join(base_path, 'train'),
            os.path.join(base_path, 'Training'),
            base_path  # if base_path is already train folder
        ]

        test_paths = [
            os.path.join(base_path, 'test'),
            os.path.join(base_path, 'Validation'),
            os.path.join(base_path, 'PublicTest')
        ]

        train_path = None
        test_path = None

        for path in train_paths:
            if os.path.exists(path):
                train_path = path
                break

        for path in test_paths:
            if os.path.exists(path):
                test_path = path
                break

        if train_path is None:
            # Maybe it's a different structure - try to load from base path
            print("âš ï¸  Could not find standard train/test folders, trying alternative structure...")
            return self.load_alternative_structure(base_path, img_size)

        print(f"ğŸ“‚ Training data from: {train_path}")
        print(f"ğŸ“‚ Test data from: {test_path}")

        X_train, y_train = self.load_folder(train_path, img_size)
        X_test, y_test = self.load_folder(test_path, img_size)

        if X_train is None:
            print("âŒ Failed to load training data")
            return None, None, None, None

        if X_test is None:
            print("âš ï¸  No test data found, splitting training data...")
            X_train, X_test, y_train, y_test = train_test_split(
                X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
            )

        print(f"âœ… Training set: {X_train.shape[0]} samples")
        print(f"âœ… Test set: {X_test.shape[0]} samples")

        # Convert to one-hot encoding
        from tensorflow.keras.utils import to_categorical
        y_train = to_categorical(y_train, num_classes=7)
        y_test = to_categorical(y_test, num_classes=7)

        return X_train, X_test, y_train, y_test

    def load_alternative_structure(self, base_path, img_size=(48, 48)):
        """Handle alternative dataset structures"""
        print("ğŸ”„ Trying alternative dataset structure...")

        images = []
        labels = []

        # Look for emotion folders directly in base path
        for emotion_folder, emotion_id in self.emotions.items():
            emotion_path = os.path.join(base_path, emotion_folder)

            if os.path.exists(emotion_path):
                print(f"ğŸ“ Loading from: {emotion_path}")
                emotion_images, emotion_labels = self.load_emotion_folder(emotion_path, emotion_id, img_size)
                images.extend(emotion_images)
                labels.extend(emotion_labels)
            else:
                # Try with capital first letter
                emotion_path_cap = os.path.join(base_path, emotion_folder.capitalize())
                if os.path.exists(emotion_path_cap):
                    print(f"ğŸ“ Loading from: {emotion_path_cap}")
                    emotion_images, emotion_labels = self.load_emotion_folder(emotion_path_cap, emotion_id, img_size)
                    images.extend(emotion_images)
                    labels.extend(emotion_labels)

        if not images:
            print("âŒ Could not find any images in alternative structure")
            return None, None, None, None

        # Convert to arrays
        images = np.array(images)
        labels = np.array(labels)

        # Add channel dimension
        images = np.expand_dims(images, axis=-1)

        print(f"âœ… Loaded {len(images)} total images")

        # Split into train and test
        X_train, X_test, y_train, y_test = train_test_split(
            images, labels, test_size=0.2, random_state=42, stratify=labels
        )

        # Convert to one-hot
        from tensorflow.keras.utils import to_categorical
        y_train = to_categorical(y_train, num_classes=7)
        y_test = to_categorical(y_test, num_classes=7)

        return X_train, X_test, y_train, y_test

    def load_folder(self, folder_path, img_size=(48, 48)):
        """Load all images from a folder with emotion subfolders"""
        if not os.path.exists(folder_path):
            print(f"âŒ Folder not found: {folder_path}")
            return None, None

        images = []
        labels = []

        print(f"\nğŸ“‚ Scanning folder: {folder_path}")

        for emotion_folder, emotion_id in self.emotions.items():
            emotion_path = os.path.join(folder_path, emotion_folder)

            if not os.path.exists(emotion_path):
                # Try with capital first letter
                emotion_path = os.path.join(folder_path, emotion_folder.capitalize())
                if not os.path.exists(emotion_path):
                    # Try with uppercase
                    emotion_path = os.path.join(folder_path, emotion_folder.upper())
                    if not os.path.exists(emotion_path):
                        print(f"âš ï¸  Emotion folder not found: {emotion_folder}")
                        continue

            emotion_images, emotion_labels = self.load_emotion_folder(emotion_path, emotion_id, img_size)
            images.extend(emotion_images)
            labels.extend(emotion_labels)

        if not images:
            print("âŒ No images found!")
            return None, None

        # Convert to numpy arrays
        images = np.array(images)
        labels = np.array(labels)

        # Add channel dimension
        images = np.expand_dims(images, axis=-1)

        print(f"âœ… Loaded {len(images)} images from {folder_path}")
        return images, labels

    def load_emotion_folder(self, emotion_path, emotion_id, img_size):
        """Load images from a specific emotion folder"""
        images = []
        labels = []
        image_count = 0

        for filename in os.listdir(emotion_path):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                # Load and process image
                img_path = os.path.join(emotion_path, filename)
                try:
                    # Read image
                    img = cv2.imread(img_path)
                    if img is None:
                        continue

                    # Convert to grayscale
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

                    # Resize to target size
                    img = cv2.resize(img, img_size)

                    # Normalize
                    img = img.astype('float32') / 255.0

                    images.append(img)
                    labels.append(emotion_id)
                    image_count += 1

                except Exception as e:
                    print(f"âš ï¸  Error loading {img_path}: {e}")
                    continue

        print(f"   {os.path.basename(emotion_path)}: {image_count} images")
        return images, labels

    def show_dataset_info(self, X_train, y_train, X_test, y_test):
        """Show information about the loaded dataset"""
        print("\nğŸ“Š DATASET INFORMATION:")
        print(f"Training set: {X_train.shape[0]} images")
        print(f"Test set: {X_test.shape[0]} images")
        print(f"Image shape: {X_train.shape[1:]}")

        # Show emotion distribution in training set
        train_labels = np.argmax(y_train, axis=1)
        test_labels = np.argmax(y_test, axis=1)

        print("\nğŸ­ Training Set Emotion Distribution:")
        for emotion_id, emotion_name in self.emotion_names.items():
            count = np.sum(train_labels == emotion_id)
            print(f"  {emotion_name}: {count} images")

        print("\nğŸ­ Test Set Emotion Distribution:")
        for emotion_id, emotion_name in self.emotion_names.items():
            count = np.sum(test_labels == emotion_id)
            print(f"  {emotion_name}: {count} images")

    def visualize_samples(self, X, y, num_samples=5):
        """Visualize sample images from each emotion"""
        labels = np.argmax(y, axis=1)

        fig, axes = plt.subplots(len(self.emotion_names), num_samples, figsize=(15, 12))

        for emotion_id, emotion_name in self.emotion_names.items():
            # Get indices for this emotion
            emotion_indices = np.where(labels == emotion_id)[0]

            if len(emotion_indices) == 0:
                continue

            # Select random samples
            if len(emotion_indices) > num_samples:
                selected_indices = np.random.choice(emotion_indices, num_samples, replace=False)
            else:
                selected_indices = emotion_indices

            for i, idx in enumerate(selected_indices):
                if i < num_samples:
                    if len(self.emotion_names) > 1:
                        ax = axes[emotion_id, i]
                    else:
                        ax = axes[i]
                    ax.imshow(X[idx].squeeze(), cmap='gray')
                    ax.set_title(f'{emotion_name}')
                    ax.axis('off')

        plt.suptitle('Sample Images from Each Emotion Class', fontsize=16)
        plt.tight_layout()
        plt.show()

def test_kaggle_loader():
    """Test the dataset loader in Kaggle environment"""
    print("ğŸ§ª Testing Kaggle FER2013 Dataset Loader")
    print("=" * 50)

    loader = KaggleFER2013Loader()

    # Try to load the dataset
    X_train, X_test, y_train, y_test = loader.load_kaggle_dataset()

    if X_train is not None:
        print("\nğŸ‰ Dataset loaded successfully!")
        loader.show_dataset_info(X_train, y_train, X_test, y_test)

        # Visualize samples
        print("\nğŸ–¼ï¸  Visualizing sample images...")
        loader.visualize_samples(X_train, y_train)

        return X_train, X_test, y_train, y_test
    else:
        print("\nâŒ Could not load dataset")
        print("\nğŸ’¡ Available directories in /kaggle/input/:")
        input_dir = '/kaggle/input'
        if os.path.exists(input_dir):
            for item in os.listdir(input_dir):
                print(f"  - {item}")
        return None, None, None, None

if __name__ == "__main__":
    test_kaggle_loader()

